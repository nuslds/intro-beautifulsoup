{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV. Scraping web pages with Requests and BeautifulSoup\n",
    "\n",
    "## The Task\n",
    "In part III, we will create a reusable function that scrapes quotes from the website by stating the range of the pages. The outputs will be save as CSV.\n",
    "\n",
    "\n",
    "| author          | author_url                                        | quote_text                                        | tags                                     |\n",
    "| :-------------- | :------------------------------------------------ | :------------------------------------------------ | ---------------------------------------- |\n",
    "| Albert Einstein | http://quotes.toscrape.com/author/Albert-Einstein | “The world as we have created it is a process ... | change;deep-thoughts;thinking;world      |\n",
    "| J.K. Rowling    | http://quotes.toscrape.com/author/J-K-Rowling     | “It is our choices, Harry, that show what we t... | abilities;choices                        |\n",
    "| Albert Einstein | http://quotes.toscrape.com/author/Albert-Einstein | “There are only two ways to live your life. On... | inspirational;life;live;miracle;miracles |\n",
    "| Jane Austen     | http://quotes.toscrape.com/author/Jane-Austen     | “The person, be it gentleman or lady, who has ... | aliteracy;books;classic;humor            |\n",
    "\n",
    "\n",
    "\n",
    "## Main Steps\n",
    "\n",
    "- Import necessary libraries\n",
    "- Define the URL\n",
    "- Make a request to retrieve HTML codes\n",
    "- Make the soup\n",
    "- Parse HTML with BeautifulSoup\n",
    "- Store the results\n",
    "- Create reusable functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will start with scraping quotes from Page 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.  Make a simple request and retrieve response contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the base URL\n",
    "base_url = 'http://quotes.toscrape.com/page/'\n",
    "\n",
    "# The page number for the first page is 1\n",
    "page_num = 1\n",
    "\n",
    "# url = the base URL + page number\n",
    "url = base_url + str(page_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Make a simple GET request to retrieve HTML codes\n",
    "The `requests library` is commonly used in Python to make HTTP requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make HTTP requests\n",
    "r = requests.get(url)\n",
    "\n",
    "# Retrieve response contents\n",
    "c = r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Make the soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Parse HTML with BeautifulSoup\n",
    "### 4.1 Locate all the quotes on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = soup.find_all('div', {'class': 'quote'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Observe the retrieved quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quotes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Reuse the get_quote function\n",
    "Because the HTML strings share the same patterns with the one we processed in Part II, here we can reuse the `get_quote` function.\n",
    "<br>However, we will need to make a minor change to the function so that it can take a bs4 element as the input.\n",
    "- \"#\" the code to make soup as the input is already a bs4 element.\n",
    "- Change the input of the function to soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quote(text):\n",
    "    # make the soup\n",
    "    soup = BeautifulSoup(text, \"lxml\")\n",
    "\n",
    "    # retrieve the text of the quote\n",
    "    quote_text = soup.find('span')\n",
    "    quote_text = quote_text.text\n",
    "\n",
    "    # retrieve the author name\n",
    "    author = soup.find('small')\n",
    "    author = author.text\n",
    "\n",
    "    # retrieve the tags\n",
    "    tags = soup.find_all('a', {'class': 'tag'})\n",
    "    tags_ls = []\n",
    "    for tag in tags:\n",
    "        tag = tag.text\n",
    "        tags_ls.append(tag)\n",
    "    tags = ';'.join(tags_ls)\n",
    "\n",
    "    #retreive the author URL\n",
    "    author_url = soup.find('a')\n",
    "    author_url = author_url.get('href')\n",
    "    author_url = 'http://quotes.toscrape.com' + author_url\n",
    "    \n",
    "    results_dt = {\n",
    "    'author': author,\n",
    "    'author_url': author_url,\n",
    "    'tags': ';'.join(tags_ls), \n",
    "    'quote_text': quote_text\n",
    "    }\n",
    "    \n",
    "    return results_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Test out the modified get_quote function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing the fifth quotes\n",
    "get_quote(quotes[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Scrape all the quotes on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for quote in quotes:\n",
    "    quote = get_quote(quote)\n",
    "    outputs.append(quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Create reusable functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Function - Get quotes by page number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quotes(page_number):\n",
    "    # define the URL\n",
    "    base_url = 'http://quotes.toscrape.com/page/'\n",
    "    page_number = str(page_number)\n",
    "    url = base_url + page_number\n",
    "    \n",
    "    # make a request and make the soup\n",
    "    r = requests.get(url)\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, 'lxml')\n",
    "    \n",
    "    # locate all the quotes\n",
    "    quotes = soup.find_all('div', {'class': 'quote'})\n",
    "    \n",
    "    # parse each quote using for loops\n",
    "    outputs = []\n",
    "    for quote in quotes:\n",
    "        quote = get_quote(quote)\n",
    "        outputs.append(quote)\n",
    "        \n",
    "    # return the outputs\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out the function now! In the cell below, print the quotes on Page 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Function - Get quotes by a range of numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 Get started with a for loops\n",
    "Examples: from Page 1 to page 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for i in list(range(1, 4)):\n",
    "    outputs += get_quotes(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Transform to outputs into a tabluar format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pd.DataFrame(outputs)\n",
    "outputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3 Write the lines together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_quotes(start, end):\n",
    "    outputs = []\n",
    "    for i in list(range(start, end + 1)):\n",
    "        outputs += get_quotes(i)\n",
    "    outputs = pd.DataFrame(outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out the function\n",
    "In the cell below, scrape quotes from page 2 to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
